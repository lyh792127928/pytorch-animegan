{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a392f84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!python train.py --device 'cpu' --epochs 20 --save_interval 1 --train_photo_path train_photo --dataset shinkai --batch 4 --init_epochs 4 --use_sn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd5019",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!python script/video_to_images.py --video-path ./dataset/video/city.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5400f6a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: edge_smooth.py [-h] [--data_dir DATA_DIR] [--dataset DATASET]\n",
      "                      [--image_size IMAGE_SIZE]\n",
      "edge_smooth.py: error: unrecognized arguments: --image-size 256\n"
     ]
    }
   ],
   "source": [
    "!python script/edge_smooth.py --dataset shinkai --image-size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8f1195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight loaded, ready to predict\n",
      "Anime image saved to 1.png\n"
     ]
    }
   ],
   "source": [
    "!python inference_image.py --checkpoint checkpoint/generator_shinkai_19.pth --src dataset/test/HR_photo/2.jpg --dest 1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31438b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4b52666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.common import load_checkpoint,load_weight\n",
    "from modeling.anime_ganv2 import Generator\n",
    "from modeling.anime_ganv2 import Discriminator\n",
    "import os\n",
    "def load_checkpoint(model, checkpoint_dir, posfix=''):\n",
    "    path = os.path.join(checkpoint_dir, f'{model.name}{posfix}.pth')\n",
    "    return load_weight(model, path)\n",
    "G = Generator('shinkai')\n",
    "D = Discriminator(args).to(args.device)\n",
    "\n",
    "start_e = load_checkpoint(G, 'checkpoint')\n",
    "test = load_checkpoint(D, 'checkpoint')\n",
    "start_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d76ff06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a248f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default='shinkai')\n",
    "parser.add_argument('--data-dir', type=str, default='dataset')\n",
    "parser.add_argument('--train_photo_path', type=str, default='train_photo')\n",
    "parser.add_argument('--epochs', type=int, default=100)\n",
    "parser.add_argument('--init_epochs', type=int, default=5)\n",
    "parser.add_argument('--batch-size', type=int, default=6)\n",
    "parser.add_argument('--checkpoint_dir', type=str, default='checkpoint')\n",
    "parser.add_argument('--save_image_dir', type=str, default='dataset/predict_photo')\n",
    "parser.add_argument('--gan_loss', type=str, default='lsgan', help='lsgan / hinge / bce')\n",
    "parser.add_argument('--device', type=str, default='cpu')\n",
    "#stor_true为如果命令行有该参数，则该参数设置为True,否则设置为False\n",
    "parser.add_argument('--use_sn', action='store_true')\n",
    "parser.add_argument('--save_interval', type=int, default=5)\n",
    "parser.add_argument('--debug_samples', type=int, default=0)\n",
    "parser.add_argument('--lr_g', type=float, default=2e-4)\n",
    "parser.add_argument('--lr_d', type=float, default=4e-4)\n",
    "parser.add_argument('--init_lr', type=float, default=1e-3)\n",
    "parser.add_argument('--wadvg', type=float, default=10.0, help='Adversarial loss weight for G')\n",
    "parser.add_argument('--wadvd', type=float, default=10.0, help='Adversarial loss weight for D')\n",
    "parser.add_argument('--wcon', type=float, default=1.5, help='Content loss weight')\n",
    "parser.add_argument('--wgra', type=float, default=3.0, help='Gram loss weight')\n",
    "parser.add_argument('--wcol', type=float, default=30.0, help='Color loss weight')\n",
    "parser.add_argument('--d_layers', type=int, default=3, help='Discriminator conv layers')\n",
    "parser.add_argument('--d_noise', action='store_true')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f782e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53000e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44a905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    if width and height:\n",
    "        return cv2.resize(image, divisible((width, height)),  interpolation=inter)\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return cv2.resize(image, divisible((w, h)),  interpolation=inter)\n",
    "\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, divisible(dim), interpolation=inter)\n",
    "def divisible(dim):\n",
    "    '''\n",
    "    Make width and height divisible by 32\n",
    "    '''\n",
    "    width, height = dim\n",
    "    return width - (width % 32), height - (height % 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92479cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('dataset/test/HR_photo/1.jpg')[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7efdf780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 1248, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_image(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fd56121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 1279, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e028c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pytorch-animegan/train.py --device 'cpu' --epochs 20 --save_interval 1 --checkpoint_dir pytorch-animegan/checkpoint --train_photo_path train_photo --data-dir pytorch-animegan/dataset --dataset shinkai --batch 4 --init_epochs 4 --use_sn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import datetime\n",
    "\n",
    "def file2zip(packagePath, zipPath):\n",
    "    '''\n",
    "  :param packagePath: 文件夹路径\n",
    "  :param zipPath: 压缩包路径\n",
    "  :return:\n",
    "  '''\n",
    "    zip = zipfile.ZipFile(zipPath, 'w', zipfile.ZIP_DEFLATED)\n",
    "    for path, dirNames, fileNames in os.walk(packagePath):\n",
    "        fpath = path.replace(packagePath, '')\n",
    "        for name in fileNames:\n",
    "            fullName = os.path.join(path, name)\n",
    "            name = fpath + '\\\\' + name\n",
    "            zip.write(fullName, name)\n",
    "    zip.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 文件夹路径\n",
    "    packagePath = '/kaggle/working/pytorch-animegan/checkpoint'\n",
    "    zipPath = '/kaggle/working/output.zip'\n",
    "    if os.path.exists(zipPath):\n",
    "        os.remove(zipPath)\n",
    "    file2zip(packagePath, zipPath)\n",
    "    print(\"打包完成\")\n",
    "    print(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad479790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750edc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625301e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
